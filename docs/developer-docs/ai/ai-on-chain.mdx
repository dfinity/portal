---
keywords: [intermediate, tutorial, machine learning, ml, mnist, rust]
---

import useBaseUrl from "@docusaurus/useBaseUrl";
import { MarkdownChipRow } from "/src/components/Chip/MarkdownChipRow";
import '/src/components/CenterImages/center.scss';
import TabItem from "@theme/TabItem";
import Tabs from "@theme/Tabs";

# Image classification sample

<MarkdownChipRow labels={["Advanced", "Tutorial", "Rust" ]} />

ICP's unique ability to run compute at scale allows AI and neural networks to run directly onchain within a canister smart contract.

To showcase this capability, this demo example displays how an AI that identifies an image can be deployed as a smart contract with a frontend and backend, both running onchain.

<div class="text--center">
<p> </p>
</div>
<div class="text--center">
<iframe width="660" height="415" src="https://www.youtube.com/embed/6qLvIXiCGcM?si=Jf_m5JfszeNvouL9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> </div>

You can find the source code for this demo [on GitHub](https://github.com/dfinity/examples/tree/master/rust/image-classification).

## How this example works

In this example, the ICP smart contract accepts an image as input from the user and runs an image classification inference. The smart contract has two canisters:

- The frontend canister that contains HTML, JS, and CSS assets that are served in the web browser.

- The backend canister that embeds the [Tract ONNX inference engine](https://github.com/sonos/tract) with the [MobileNet v2-7 model](https://github.com/onnx/models/tree/main/validated/vision/classification/mobilenet). This canister provides a `classify()` endpoint that the frontend canister calls.

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-how-it-works.png")}
    alt="AI Demo: how it works"
    width="800"
  />
</div>

## ICP features that make it possible

To make running AI in a canister possible, two key ICP features are utilized:

- WebAssembly virtual machine: Canister code is compiled into Wasm modules to be deployed on ICP. The WebAssembly virtual machine supports standards such as the WebAssembly System Interface, which can be supported through a community tool called [wasi2ic](https://github.com/wasm-forge/wasi2ic).

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-wasm.png")}
    alt="AI Demo: Wasm"
    width="800"
  />
</div>

- Deterministic time slicing (DTS): DTS splits the execution of very large messages that require billions of Wasm instructions across multiple execution rounds.

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-dts.png")}
    alt="AI Demo: DTS"
    width="800"
  />
</div>

### Important notes

The ICP mainnet subnets and `dfx` running a replica version older than `463296` may fail with an `instruction-limit-exceeded` error.

Currently, Wasm execution is not optimized for this workload. A single call executes about 24B instructions (~10s).

## Deploying the demo

<Tabs>
<TabItem value="prereq" label="Prerequisites" default>

<input type="checkbox"/> <a href="/docs/current/developer-docs/getting-started/install">Install the IC SDK.</a>

<input type="checkbox"/> Download and install <a href="https://doc.rust-lang.org/book/ch01-01-installation.html">Rust.</a>

<input type="checkbox"/> Download and install <a href="https://git-scm.com/downloads">git.</a>

<input type="checkbox"/> Download and install <a href="https://github.com/WebAssembly/wasi-sdk/releases/tag/wasi-sdk-21"><code>wasi-skd-21.0</code>.</a>

<input type="checkbox"/> Export `CC_wasm32_wasi` in your shell such that it points to WASI clang and sysroot: <code>export CC_wasm32_wasi="/path/to/wasi-sdk-21.0/bin/clang --sysroot=/path/to/wasi-sdk-21.0/share/wasi-sysroot"</code>

<input type="checkbox"/> Download and install <a href="https://github.com/wasm-forge/wasi2ic"><code>wasi2ic</code> and make sure that `wasi2ic` binary is in your <code>$PATH</code>.</a>

</TabItem>
</Tabs>


### Downloading the example

You can clone the GitHub repo for this example with the command:

```
git clone https://github.com/dfinity/examples.git
```

Then navigate into the directory for the AI demo:

```
cd examples/rust/image-classification
```

Download MobileNet v2-7 to `src/backend/assets/mobilenetv2-7.onnx` by running the script:

```
./download_model.sh
```

Install Node.js dependencies for the frontend:

```
npm install
```

Add the following Rust target:

```
rustup target add wasm32-wasi
```

### Deploying the code

To deploy the example, first start `dfx`, then deploy the project:

```
dfx start --clean --background
dfx deploy
```

## Using the demo

Once deployed, open the frontend canister's URL in your browser. You'll see the demo's user interface:

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-demo-1.png")}
    alt="Using the AI demo"
    width="800"
  />
</div>

Click on the Internet Computer logo. You'll be prompted to select an image file from your local files. In this example, we'll use an astronaut image. Then, select 'Go':

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-demo-2.png")}
    alt="Using the AI demo"
    width="800"
  />
</div>

The smart contract will do some computation to infer what the image is. This process may take about 10 seconds.

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-demo-3.png")}
    alt="Using the AI demo"
    width="800"
  />
</div>

The image inference results will be returned:

<div class="text-center">
  <img
    src={useBaseUrl("/img/docs/ai-demo-4.png")}
    alt="Using the AI demo"
    width="800"
  />
</div>

## Resources

- [GitHub repo for this example](https://github.com/dfinity/examples/tree/master/rust/image-classification).

- [Video demo](https://www.youtube.com/watch?v=6qLvIXiCGcM).