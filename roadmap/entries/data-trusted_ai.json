{
  "categoryName": "Decentralized AI",
  "categoryDescription": "Today, users have to blindly trust AI models running on centralized servers with no visibility into how data is used and how AI models produce responses. Decentralized AI solves this problem by bringing the trustworthiness, security, verifiability, and resilience of smart contracts to AI applications.",
  "elements": [
    {
      "title": "Foundational LLMs",
      "description": "AI agents are a growing paradigm in software, and the Internet Computer is uniquely positioned to be the home of AI agents. Compared to the traditional IT stack, AI agents on the Internet Computer can securely and easily manage digital assets, transact amongst each other, be fully sovereign, and be tokenized and managed by DAOs. This milestone focuses on providing access to foundational LLMs, along with basic tools to make it as simple as possible to deploy agents on the Internet Computer.",
      "status": "in_progress",
      "is_milestone": true,
      "milestone_id": "Ignition",
      "eta": "",
      "eta_to_render": ""
    },
    {
      "title": "LLM Canister MVP",
      "overview": "A canister will be made available that provides an API for processing LLM prompts. This canister is an MVP and will initially rely on a centrally-managed service by DFINITY for processing the prompts. A small set of foundational models will be supported.",
      "status": "in_progress",
      "milestone_id": "Ignition"
    },
    {
      "title": "LLM Developer Experience",
      "overview": "Tools and libraries to simplify the local development and the interaction with the LLM canister.",
      "status": "in_progress",
      "milestone_id": "Ignition"
    },
    {
      "title": "Motoko coding fine-tuned model",
      "overview": "Fine-tune multiple Large Language Models (LLMs) using high-quality Motoko code samples to develop the most efficient and high-performing model for Motoko programming.",
      "status": "in_progress",
      "milestone_id": "Beacon"
    },
    {
      "title": "Model benchmarks for Motoko coding",
      "overview": "Develop a comprehensive set of benchmarks to evaluate model performance for Motoko programming. This includes assessing both existing base LLMs and fine-tuned models to ensure accurate measurement of the effectiveness of fine-tuning efforts.",
      "status": "in_progress",
      "milestone_id": "Beacon"
    },
    {
      "title": "Caffeine integration",
      "overview": "Integrate the results of the fine-tuning work into Caffeine to improve the quality of generated Motoko code. This will involve leveraging the highest-performing fine-tuned model, implementing a Retrieval-Augmented Generation (RAG) solution, and optimizing prompt engineering.",
      "status": "in_progress",
      "milestone_id": "Beacon"
    },
    {
      "title": "AI Model for Motoko code generation",
      "description": "This milestone is the first step towards improving the capability of Large Language Models to effectively generate code in the Motoko programming language.",
      "status": "in_progress",
      "is_milestone": true,
      "milestone_id": "Beacon",
      "eta_to_render": "April 2025"
    },
    {
      "title": "Sovereign AI Agents",
      "description": "This milestone builds on previous milestones by focusing on the security and the decentralization of the LLM services available on the Internet Computer.",
      "status": "future",
      "is_milestone": true,
      "milestone_id": "Vortex",
      "eta_to_render": ""
    },
    {
      "title": "LLM Workers",
      "overview": "Introduce worker nodes that specialize in processing LLM prompts. Workers will have security guarantees similar to canister smart contracts on the Internet Computer",
      "status": "future",
      "milestone_id": "Vortex"
    }
  ]
}
