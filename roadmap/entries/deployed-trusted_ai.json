{
  "categoryName": "",
  "categoryDescription": "",
  "elements": [
    {
      "title": "Motoko coding fine-tuned model",
      "overview": "Fine-tune multiple Large Language Models (LLMs) using high-quality Motoko code samples to develop the most efficient and high-performing model for Motoko programming.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Model benchmarks for Motoko coding",
      "overview": "Develop a comprehensive set of benchmarks to evaluate model performance for Motoko programming. This includes assessing both existing base LLMs and fine-tuned models to ensure accurate measurement of the effectiveness of fine-tuning efforts.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Caffeine platform",
      "overview": "First release of the Caffeine platform for prompt-based ICP application creation. Integrating the fine-tuned models for Motoko code generation into a chat-like user experience. Complemented by a first version of an app marketplace allowing users to publish their apps so that others can clone and evolve them.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Caffeine alpha launch â€“ dawn of the self-writing internet",
      "description": "Alpha release of the Caffeine platform that allows prompt-based creation of full-stack applications. This represents a vertex where unique ICP technologies, such as its serverless compute model, enhanced orthogonal persistence, canister snapshots, and AI models for Motoko code generation meet, creating the self-writing internet.",
      "status": "deployed",
      "is_milestone": true,
      "milestone_id": "Vertex",
      "eta_to_render": "July 15th, 2025"
    },
    {
      "title": "Increase the message instruction limit to 40 billion instructions",
      "overview": "Increasing the message limit from 20 to 40 billion instructions to facilitate longer-running computations, which is crucial for AI inference.",
      "forum": "",
      "proposal": "",
      "docs": "",
      "eta": "",
      "status": "deployed",
      "is_community": false,
      "in_beta": false,
      "milestone_id": ""
    },
    {
      "title": "Faster deterministic floating-point operations",
      "overview": "Accelerating deterministic floating-point computations in the Wasm engine.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Wasm SIMD instructions",
      "overview": "Deterministic SIMD (Single Instruction, Multiple Data) support in the Wasm execution engine for better performance of AI inference.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Optimizing AI inference engine",
      "overview": "This feature brings SIMD support to the open source inference engine used on ICP to leverage the upcoming support of SIMD operations in Wasm.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Onchain AI Inference",
      "description": "Allow smart contracts to run inference using AI models with millions of parameters fully on chain. The focus of this milestone is performance. There are performance optimizations that can be implemented both in the WebAssembly engine and the AI inference engine. The expected speedup is 10x and more.",
      "is_milestone": true,
      "milestone_id": "Cyclotron",
      "status": "deployed",
      "eta": "2024-07-15",
      "eta_to_render": "July 15, 2024"
    }
  ]
}
