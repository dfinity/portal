{
  "categoryName": "",
  "categoryDescription": "",
  "elements": [
    {
      "title": "Increase the message instruction limit to 40 billion instructions",
      "overview": "Increasing the message limit from 20 to 40 billion instructions to facilitate longer-running computations, which is crucial for AI inference.",
      "forum": "",
      "proposal": "",
      "docs": "",
      "eta": "",
      "status": "deployed",
      "is_community": false,
      "in_beta": false,
      "milestone_id": ""
    },
    {
      "title": "Faster deterministic floating-point operations",
      "overview": "Accelerating deterministic floating-point computations in the Wasm engine.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Wasm SIMD instructions",
      "overview": "Deterministic SIMD (Single Instruction, Multiple Data) support in the Wasm execution engine for better performance of AI inference.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Optimizing AI inference engine",
      "overview": "This feature brings SIMD support to the open source inference engine used on ICP to leverage the upcoming support of SIMD operations in Wasm.",
      "status": "deployed",
      "forum": "",
      "proposal": "",
      "docs": "https://medium.com/@dfinity/the-next-step-for-deai-on-chain-inference-enabling-face-recognition-589183203fc2",
      "is_community": false,
      "in_beta": false,
      "milestone_id": "Cyclotron"
    },
    {
      "title": "Onchain AI Inference",
      "description": "Allow smart contracts to run inference using AI models with millions of parameters fully on chain. The focus of this milestone is performance. There are performance optimizations that can be implemented both in the WebAssembly engine and the AI inference engine. The expected speedup is 10x and more.",
      "is_milestone": true,
      "milestone_id": "Cyclotron",
      "status": "deployed",
      "eta": "2024-07-15",
      "eta_to_render": "July 15, 2024"
    },
    {
      "title": "Motoko coding fine-tuned model",
      "overview": "Fine-tune multiple Large Language Models (LLMs) using high-quality Motoko code samples to develop the most efficient and high-performing model for Motoko programming.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Model benchmarks for Motoko coding",
      "overview": "Develop a comprehensive set of benchmarks to evaluate model performance for Motoko programming. This includes assessing both existing base LLMs and fine-tuned models to ensure accurate measurement of the effectiveness of fine-tuning efforts.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Caffeine platform",
      "overview": "First release of the Caffeine platform for prompt-based ICP application creation. Integrating the fine-tuned models for Motoko code generation into a chat-like user experience. Complemented by a first version of an app marketplace allowing users to publish their apps so that others can clone and evolve them.",
      "status": "deployed",
      "milestone_id": "Vertex"
    },
    {
      "title": "Caffeine alpha launch â€“ dawn of the self-writing internet",
      "description": "Alpha release of the Caffeine platform that allows prompt-based creation of full-stack applications. This represents a vertex where unique ICP technologies, such as its serverless compute model, enhanced orthogonal persistence, canister snapshots, and AI models for Motoko code generation meet, creating the self-writing internet.",
      "status": "deployed",
      "is_milestone": true,
      "milestone_id": "Vertex",
      "eta_to_render": "July 15th, 2025"
    },
    {
      "title": "Foundational LLMs",
      "description": "AI agents are a growing paradigm in software, and the Internet Computer is uniquely positioned to be the home of AI agents. Compared to the traditional IT stack, AI agents on the Internet Computer can securely and easily manage digital assets, transact amongst each other, be fully sovereign, and be tokenized and managed by DAOs. This milestone focuses on providing access to foundational LLMs, along with basic tools to make it as simple as possible to deploy agents on the Internet Computer.",
      "status": "deployed",
      "is_milestone": true,
      "milestone_id": "Ignition",
      "eta_to_render": "August 20,2025"
    },
    {
      "title": "LLM canister MVP",
      "overview": "A canister will be made available that provides an API for processing LLM prompts. This canister is an MVP and will initially rely on a centrally-managed service by DFINITY for processing the prompts. A small set of foundational models will be supported.",
      "status": "deployed",
      "milestone_id": "Ignition"
    },
    {
      "title": "LLM developer experience",
      "overview": "Tools and libraries to simplify the local development and the interaction with the LLM canister.",
      "status": "deployed",
      "milestone_id": "Ignition"
    },
    {
      "title": "LLM workers",
      "overview": "Introduce worker nodes that specialize in processing LLM prompts. Workers will have security guarantees similar to canister smart contracts on the Internet Computer",
      "status": "deployed",
      "milestone_id": "Ignition"
    }
  ]
}
